{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harisreedhar/Swap-Mukham/blob/main/swap_mukham_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🗿 **Swap-Mukham**\n",
        "*Face swap app based on insightface inswapper.*\n",
        "- [Github](https://github.com/harisreedhar/Swap-Mukham)\n",
        "- [Disclaimer](https://github.com/harisreedhar/Swap-Mukham#disclaimer)"
      ],
      "metadata": {
        "id": "bypvIQG5RHl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone Repository"
      ],
      "metadata": {
        "id": "csC_DX5zWLEU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klcx2cKDKX5x"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "! git clone https://github.com/harisreedhar/Swap-Mukham"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Requirements"
      ],
      "metadata": {
        "id": "bebBDddfWTXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%cd Swap-Mukham/\n",
        "print(\"Installing requirements...\")\n",
        "!pip install -r requirements.txt -q\n",
        "print(\"Installing requirements done.\")"
      ],
      "metadata": {
        "id": "VgTpg7EsTN3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Models"
      ],
      "metadata": {
        "id": "T9L6tgD0Wats"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "inswapper_model = \"https://huggingface.co/deepinsight/inswapper/resolve/main/inswapper_128.onnx\" #@param {type:\"string\"}\n",
        "gfpgan_model = \"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\" #@param {type:\"string\"}\n",
        "\n",
        "import urllib.request\n",
        "print(\"Downloading swapper model...\")\n",
        "urllib.request.urlretrieve(inswapper_model, \"/content/Swap-Mukham/inswapper_128.onnx\")\n",
        "print(\"Downloading face enhancer model...\")\n",
        "urllib.request.urlretrieve(gfpgan_model, \"/content/Swap-Mukham/GFPGANv1.4.pth\")\n",
        "print(\"Downloading models done.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "17MZO9OvUQAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply colab modification"
      ],
      "metadata": {
        "id": "NeLBSNWfV474"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import time\n",
        "import torch\n",
        "import shutil\n",
        "import gfpgan\n",
        "import platform\n",
        "import datetime\n",
        "import subprocess\n",
        "import insightface\n",
        "import onnxruntime\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from threading import Thread\n",
        "from insightface.utils import face_align\n",
        "from moviepy.editor import VideoFileClip, ImageSequenceClip\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "\n",
        "WORKSPACE = None\n",
        "OUTPUT_FILE = None\n",
        "CURRENT_FRAME = None\n",
        "STREAMER = None\n",
        "DETECT_CONDITION = \"left most\"\n",
        "NUM_OF_SRC_SPECIFIC = 10\n",
        "\n",
        "FACE_SWAPPER = None\n",
        "FACE_ANALYSER = None\n",
        "FACE_ENHANCER = None\n",
        "\n",
        "\n",
        "PROVIDER = [\"CPUExecutionProvider\"]\n",
        "available_providers = onnxruntime.get_available_providers()\n",
        "if torch.cuda.is_available() and \"CUDAExecutionProvider\" in available_providers:\n",
        "    PROVIDER = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
        "    print(\"Running on GPU\")\n",
        "else:\n",
        "  print(\"Running on CPU\")\n",
        "\n",
        "\n",
        "def load_face_analyser_model(name=\"buffalo_l\"):\n",
        "    global FACE_ANALYSER\n",
        "    if FACE_ANALYSER is None:\n",
        "        FACE_ANALYSER = insightface.app.FaceAnalysis(name=name, providers=PROVIDER)\n",
        "        FACE_ANALYSER.prepare(ctx_id=0, det_size=(640, 640), det_thresh=0.5)\n",
        "\n",
        "\n",
        "def load_face_swapper_model(name=\"inswapper_128.onnx\"):\n",
        "    global FACE_SWAPPER\n",
        "    path = os.path.join(os.path.abspath(os.path.dirname(__file__)), name)\n",
        "    if FACE_SWAPPER is None:\n",
        "        FACE_SWAPPER = insightface.model_zoo.get_model(path, providers=PROVIDER)\n",
        "\n",
        "\n",
        "def load_face_enhancer_model(name=\"GFPGANv1.4.pth\"):\n",
        "    global FACE_ENHANCER\n",
        "    path = os.path.join(os.path.abspath(os.path.dirname(__file__)), name)\n",
        "    if FACE_ENHANCER is None:\n",
        "        FACE_ENHANCER = gfpgan.GFPGANer(model_path=path, upscale=1)\n",
        "\n",
        "\n",
        "detect_conditions = [\n",
        "    \"left most\",\n",
        "    \"right most\",\n",
        "    \"top most\",\n",
        "    \"bottom most\",\n",
        "    \"most width\",\n",
        "    \"most height\",\n",
        "]\n",
        "\n",
        "\n",
        "def analyse_face(image, return_single_face=True):\n",
        "    faces = FACE_ANALYSER.get(image)\n",
        "    if not return_single_face:\n",
        "        return faces\n",
        "\n",
        "    total_faces = len(faces)\n",
        "    if total_faces == 1:\n",
        "        return faces[0]\n",
        "\n",
        "    global DETECT_CONDITION\n",
        "    condition = DETECT_CONDITION\n",
        "\n",
        "    print(f\"{total_faces} face detected. Using {condition} face.\")\n",
        "    if condition == \"left most\":\n",
        "        return sorted(faces, key=lambda face: face[\"bbox\"][0])[0]\n",
        "    elif condition == \"right most\":\n",
        "        return sorted(faces, key=lambda face: face[\"bbox\"][0])[-1]\n",
        "    elif condition == \"top most\":\n",
        "        return sorted(faces, key=lambda face: face[\"bbox\"][1])[0]\n",
        "    elif condition == \"bottom most\":\n",
        "        return sorted(faces, key=lambda face: face[\"bbox\"][1])[-1]\n",
        "    elif condition == \"most width\":\n",
        "        return sorted(faces, key=lambda face: face[\"bbox\"][2])[-1]\n",
        "    elif condition == \"most height\":\n",
        "        return sorted(faces, key=lambda face: face[\"bbox\"][3])[-1]\n",
        "\n",
        "\n",
        "swap_options_list = [\n",
        "    \"All face\",\n",
        "    \"Age less than\",\n",
        "    \"Age greater than\",\n",
        "    \"All Male\",\n",
        "    \"All Female\",\n",
        "    \"Specific Face\",\n",
        "]\n",
        "\n",
        "\n",
        "def swap_face(whole_img, target_face, source_face, face_enhance=False):\n",
        "    if not face_enhance or FACE_ENHANCER is None:\n",
        "        return FACE_SWAPPER.get(whole_img, target_face, source_face, paste_back=True)\n",
        "\n",
        "    bgr_fake, M = FACE_SWAPPER.get(\n",
        "        whole_img, target_face, source_face, paste_back=False\n",
        "    )\n",
        "    _, bgr_fake, _ = FACE_ENHANCER.enhance(bgr_fake, paste_back=True, has_aligned=True)\n",
        "    bgr_fake = bgr_fake[0]\n",
        "\n",
        "    aimg, _ = face_align.norm_crop2(whole_img, target_face.kps, image_size=512)\n",
        "    IM = cv2.invertAffineTransform(M / 0.25)  # 128/512 = 0.25\n",
        "    img_white = np.full((aimg.shape[0], aimg.shape[1]), 255, dtype=np.float32)\n",
        "    bgr_fake = cv2.warpAffine(\n",
        "        bgr_fake, IM, (whole_img.shape[1], whole_img.shape[0]), borderValue=0.0\n",
        "    )\n",
        "    img_white = cv2.warpAffine(\n",
        "        img_white, IM, (whole_img.shape[1], whole_img.shape[0]), borderValue=0.0\n",
        "    )\n",
        "    img_white[img_white > 20] = 255\n",
        "    img_mask = img_white\n",
        "    mask_h_inds, mask_w_inds = np.where(img_mask == 255)\n",
        "    mask_h = np.max(mask_h_inds) - np.min(mask_h_inds)\n",
        "    mask_w = np.max(mask_w_inds) - np.min(mask_w_inds)\n",
        "    mask_size = int(np.sqrt(mask_h * mask_w))\n",
        "\n",
        "    k = max(mask_size // 10, 10)\n",
        "    img_mask = cv2.erode(img_mask, np.ones((k, k), np.uint8), iterations=1)\n",
        "\n",
        "    k = max(mask_size // 20, 5)\n",
        "    kernel_size = (k, k)\n",
        "    blur_size = tuple(2 * i + 1 for i in kernel_size)\n",
        "    img_mask = cv2.GaussianBlur(img_mask, blur_size, 0) / 255\n",
        "\n",
        "    img_mask = np.reshape(img_mask, [img_mask.shape[0], img_mask.shape[1], 1])\n",
        "    fake_merged = img_mask * bgr_fake + (1 - img_mask) * whole_img.astype(np.float32)\n",
        "    return fake_merged.astype(np.uint8)\n",
        "\n",
        "\n",
        "def swap_face_with_condition(\n",
        "    source_face, target_faces, whole_img, condition, age, face_enhance=False\n",
        "):\n",
        "    swapped = whole_img.copy()\n",
        "\n",
        "    for target_face in target_faces:\n",
        "        if condition == \"All face\":\n",
        "            swapped = swap_face(\n",
        "                swapped, target_face, source_face, face_enhance=face_enhance\n",
        "            )\n",
        "        elif condition == \"Age less than\" and target_face[\"age\"] < age:\n",
        "            swapped = swap_face(\n",
        "                swapped, target_face, source_face, face_enhance=face_enhance\n",
        "            )\n",
        "        elif condition == \"Age greater than\" and target_face[\"age\"] > age:\n",
        "            swapped = swap_face(\n",
        "                swapped, target_face, source_face, face_enhance=face_enhance\n",
        "            )\n",
        "        elif condition == \"All Male\" and target_face[\"gender\"] == 1:\n",
        "            swapped = swap_face(\n",
        "                swapped, target_face, source_face, face_enhance=face_enhance\n",
        "            )\n",
        "        elif condition == \"All Female\" and target_face[\"gender\"] == 0:\n",
        "            swapped = swap_face(\n",
        "                swapped, target_face, source_face, face_enhance=face_enhance\n",
        "            )\n",
        "\n",
        "    return swapped\n",
        "\n",
        "\n",
        "def swap_specific(\n",
        "    source_specifics, target_faces, whole_img, threshold=0.6, face_enhance=False\n",
        "):\n",
        "    swapped = whole_img.copy()\n",
        "\n",
        "    for source_face, specific_face in source_specifics:\n",
        "        specific_embed = specific_face[\"embedding\"]\n",
        "        specific_embed /= np.linalg.norm(specific_embed)\n",
        "\n",
        "        for target_face in target_faces:\n",
        "            target_embed = target_face[\"embedding\"]\n",
        "            target_embed /= np.linalg.norm(target_embed)\n",
        "            cosine_distance = 1 - np.dot(specific_embed, target_embed)\n",
        "            if cosine_distance > threshold:\n",
        "                continue\n",
        "            swapped = swap_face(\n",
        "                swapped, target_face, source_face, face_enhance=face_enhance\n",
        "            )\n",
        "\n",
        "    return swapped\n",
        "\n",
        "\n",
        "def trim_video(video_path, output_path, start_frame, stop_frame):\n",
        "    video_name, _ = os.path.splitext(os.path.basename(video_path))\n",
        "    trimmed_video_filename = video_name + \"_trimmed\" + \".mp4\"\n",
        "    temp_path = os.path.join(output_path, \"trim\")\n",
        "    os.makedirs(temp_path, exist_ok=True)\n",
        "    trimmed_video_file_path = os.path.join(temp_path, trimmed_video_filename)\n",
        "\n",
        "    video = VideoFileClip(video_path)\n",
        "    fps = video.fps\n",
        "    start_time = start_frame / fps\n",
        "    duration = (stop_frame - start_frame) / fps\n",
        "\n",
        "    trimmed_video = video.subclip(start_time, start_time + duration)\n",
        "    trimmed_video.write_videofile(\n",
        "        trimmed_video_file_path, codec=\"libx264\", audio_codec=\"aac\"\n",
        "    )\n",
        "    trimmed_video.close()\n",
        "    video.close()\n",
        "\n",
        "    return trimmed_video_file_path\n",
        "\n",
        "\n",
        "def open_directory(path=None):\n",
        "    if path is None:\n",
        "        return\n",
        "    try:\n",
        "        os.startfile(path)\n",
        "    except:\n",
        "        subprocess.Popen([\"xdg-open\", path])\n",
        "\n",
        "\n",
        "class StreamerThread(object):\n",
        "    def __init__(self, src=0):\n",
        "        self.capture = cv2.VideoCapture(src)\n",
        "        self.capture.set(cv2.CAP_PROP_BUFFERSIZE, 2)\n",
        "        self.FPS = 1 / 30\n",
        "        self.FPS_MS = int(self.FPS * 1000)\n",
        "        self.thread = None\n",
        "        self.stopped = False\n",
        "        self.frame = None\n",
        "\n",
        "    def start(self):\n",
        "        self.thread = Thread(target=self.update, args=())\n",
        "        self.thread.daemon = True\n",
        "        self.thread.start()\n",
        "\n",
        "    def stop(self):\n",
        "        self.stopped = True\n",
        "        self.thread.join()\n",
        "        print(\"stopped\")\n",
        "\n",
        "    def update(self):\n",
        "        while not self.stopped:\n",
        "            if self.capture.isOpened():\n",
        "                (self.status, self.frame) = self.capture.read()\n",
        "            time.sleep(self.FPS)\n",
        "\n",
        "\n",
        "class ProcessBar:\n",
        "    def __init__(self, bar_length, total, before=\"⬛\", after=\"🟨\"):\n",
        "        self.bar_length = bar_length\n",
        "        self.total = total\n",
        "        self.before = before\n",
        "        self.after = after\n",
        "        self.bar = [self.before] * bar_length\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def get(self, index):\n",
        "        total = self.total\n",
        "        elapsed_time = time.time() - self.start_time\n",
        "        average_time_per_iteration = elapsed_time / (index + 1)\n",
        "        remaining_iterations = total - (index + 1)\n",
        "        estimated_remaining_time = remaining_iterations * average_time_per_iteration\n",
        "\n",
        "        self.bar[int(index / total * self.bar_length)] = self.after\n",
        "        info_text = f\"({index+1}/{total}) {''.join(self.bar)} \"\n",
        "        info_text += f\"(ETR: {int(estimated_remaining_time // 60)} min {int(estimated_remaining_time % 60)} sec)\"\n",
        "        return info_text\n",
        "\n",
        "\n",
        "def process(\n",
        "    input_type,\n",
        "    image_path,\n",
        "    video_path,\n",
        "    directory_path,\n",
        "    source_path,\n",
        "    output_path,\n",
        "    output_name,\n",
        "    keep_output_sequence,\n",
        "    condition,\n",
        "    age,\n",
        "    distance,\n",
        "    face_enhance,\n",
        "    *specifics,\n",
        "):\n",
        "    global WORKSPACE\n",
        "    global OUTPUT_FILE\n",
        "    global PREVIEW\n",
        "    WORKSPACE, OUTPUT_FILE, PREVIEW = None, None, None\n",
        "\n",
        "    def ui_before():\n",
        "        return (\n",
        "            gr.update(visible=True, value=PREVIEW),\n",
        "            gr.update(interactive=False),\n",
        "            gr.update(interactive=False),\n",
        "            gr.update(visible=False),\n",
        "        )\n",
        "\n",
        "    def ui_after():\n",
        "        return (\n",
        "            gr.update(visible=True, value=PREVIEW),\n",
        "            gr.update(interactive=True),\n",
        "            gr.update(interactive=True),\n",
        "            gr.update(visible=False),\n",
        "        )\n",
        "\n",
        "    def ui_after_vid():\n",
        "        return (\n",
        "            gr.update(visible=False),\n",
        "            gr.update(interactive=True),\n",
        "            gr.update(interactive=True),\n",
        "            gr.update(value=OUTPUT_FILE, visible=True),\n",
        "        )\n",
        "\n",
        "    start_time = time.time()\n",
        "    specifics = list(specifics)\n",
        "    half = len(specifics) // 2\n",
        "    sources = specifics[:half]\n",
        "    specifics = specifics[half:]\n",
        "\n",
        "    yield \"### \\n ⌛ Loading face analyser model...\", *ui_before()\n",
        "    load_face_analyser_model()\n",
        "\n",
        "    yield \"### \\n ⌛ Loading face swapper model...\", *ui_before()\n",
        "    load_face_swapper_model()\n",
        "\n",
        "    if face_enhance:\n",
        "        yield \"### \\n ⌛ Loading face enhancer model...\", *ui_before()\n",
        "        load_face_enhancer_model()\n",
        "\n",
        "    yield \"### \\n ⌛ Analysing Face...\", *ui_before()\n",
        "\n",
        "    analysed_source_specific = []\n",
        "    if condition == \"Specific Face\":\n",
        "        for source, specific in zip(sources, specifics):\n",
        "            if source is None or specific is None:\n",
        "                continue\n",
        "            analysed_source = analyse_face(source, return_single_face=True)\n",
        "            analysed_specific = analyse_face(specific, return_single_face=True)\n",
        "            analysed_source_specific.append([analysed_source, analysed_specific])\n",
        "    else:\n",
        "        source = cv2.imread(source_path)\n",
        "        analysed_source = analyse_face(source, return_single_face=True)\n",
        "\n",
        "    if input_type == \"Image\":\n",
        "        target = cv2.imread(image_path)\n",
        "        analysed_target = analyse_face(target, return_single_face=False)\n",
        "        if condition == \"Specific Face\":\n",
        "            swapped = swap_specific(\n",
        "                analysed_source_specific,\n",
        "                analysed_target,\n",
        "                target,\n",
        "                threshold=distance,\n",
        "                face_enhance=face_enhance,\n",
        "            )\n",
        "        else:\n",
        "            swapped = swap_face_with_condition(\n",
        "                analysed_source,\n",
        "                analysed_target,\n",
        "                target,\n",
        "                condition,\n",
        "                age,\n",
        "                face_enhance=face_enhance,\n",
        "            )\n",
        "\n",
        "        filename = os.path.join(output_path, output_name + \".png\")\n",
        "        cv2.imwrite(filename, swapped)\n",
        "        OUTPUT_FILE = filename\n",
        "        WORKSPACE = output_path\n",
        "        PREVIEW = swapped[:, :, ::-1]\n",
        "\n",
        "        tot_exec_time = time.time() - start_time\n",
        "        _min, _sec = divmod(tot_exec_time, 60)\n",
        "\n",
        "        yield f\"Completed in {int(_min)} min {int(_sec)} sec.\", *ui_after()\n",
        "\n",
        "    elif input_type == \"Video\":\n",
        "        temp_path = os.path.join(output_path, output_name, \"sequence\")\n",
        "        os.makedirs(temp_path, exist_ok=True)\n",
        "\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        duration = video_clip.duration\n",
        "        fps = video_clip.fps\n",
        "        total_frames = video_clip.reader.nframes\n",
        "\n",
        "        analysed_targets = []\n",
        "        process_bar = ProcessBar(30, total_frames)\n",
        "        yield \"### \\n ⌛ Analysing...\", *ui_before()\n",
        "        for i, frame in enumerate(video_clip.iter_frames()):\n",
        "            analysed_targets.append(analyse_face(frame, return_single_face=False))\n",
        "            info_text = \"Analysing Faces || \"\n",
        "            info_text += process_bar.get(i)\n",
        "            print(\"\\033[1A\\033[K\", end=\"\", flush=True)\n",
        "            print(info_text)\n",
        "            if i % 10 == 0:\n",
        "                yield \"### \\n\" + info_text, *ui_before()\n",
        "        video_clip.close()\n",
        "\n",
        "        image_sequence = []\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        audio_clip = video_clip.audio if video_clip.audio is not None else None\n",
        "        process_bar = ProcessBar(30, total_frames)\n",
        "        yield \"### \\n ⌛ Swapping...\", *ui_before()\n",
        "        for i, frame in enumerate(video_clip.iter_frames()):\n",
        "            swapped = frame\n",
        "            analysed_target = analysed_targets[i]\n",
        "\n",
        "            if condition == \"Specific Face\":\n",
        "                swapped = swap_specific(\n",
        "                    analysed_source_specific,\n",
        "                    analysed_target,\n",
        "                    frame,\n",
        "                    threshold=distance,\n",
        "                    face_enhance=face_enhance,\n",
        "                )\n",
        "            else:\n",
        "                swapped = swap_face_with_condition(\n",
        "                    analysed_source,\n",
        "                    analysed_target,\n",
        "                    frame,\n",
        "                    condition,\n",
        "                    age,\n",
        "                    face_enhance=face_enhance,\n",
        "                )\n",
        "\n",
        "            image_path = os.path.join(temp_path, f\"frame_{i}.png\")\n",
        "            cv2.imwrite(image_path, swapped[:, :, ::-1])\n",
        "            image_sequence.append(image_path)\n",
        "\n",
        "            info_text = \"Swapping Faces || \"\n",
        "            info_text += process_bar.get(i)\n",
        "            print(\"\\033[1A\\033[K\", end=\"\", flush=True)\n",
        "            print(info_text)\n",
        "            if i % 6 == 0:\n",
        "                PREVIEW = swapped\n",
        "                yield \"### \\n\" + info_text, *ui_before()\n",
        "\n",
        "        yield \"### \\n ⌛ Merging...\", *ui_before()\n",
        "        edited_video_clip = ImageSequenceClip(image_sequence, fps=fps)\n",
        "\n",
        "        if audio_clip is not None:\n",
        "            edited_video_clip = edited_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        output_video_path = os.path.join(output_path, output_name + \".mp4\")\n",
        "        edited_video_clip.set_duration(duration).write_videofile(\n",
        "            output_video_path, codec=\"libx264\"\n",
        "        )\n",
        "        edited_video_clip.close()\n",
        "        video_clip.close()\n",
        "\n",
        "        if os.path.exists(temp_path) and not keep_output_sequence:\n",
        "            yield \"### \\n ⌛ Removing temporary files...\", *ui_before()\n",
        "            shutil.rmtree(temp_path)\n",
        "\n",
        "        WORKSPACE = output_path\n",
        "        OUTPUT_FILE = output_video_path\n",
        "\n",
        "        tot_exec_time = time.time() - start_time\n",
        "        _min, _sec = divmod(tot_exec_time, 60)\n",
        "\n",
        "        yield f\"✔️ Completed in {int(_min)} min {int(_sec)} sec.\", *ui_after_vid()\n",
        "\n",
        "    elif input_type == \"Directory\":\n",
        "        source = cv2.imread(source_path)\n",
        "        source = analyse_face(source, return_single_face=True)\n",
        "        extensions = [\"jpg\", \"jpeg\", \"png\", \"bmp\", \"tiff\", \"ico\", \"webp\"]\n",
        "        temp_path = os.path.join(output_path, output_name)\n",
        "        if os.path.exists(temp_path):\n",
        "            shutil.rmtree(temp_path)\n",
        "        os.mkdir(temp_path)\n",
        "        swapped = None\n",
        "\n",
        "        files = []\n",
        "        for file_path in glob.glob(os.path.join(directory_path, \"*\")):\n",
        "            if any(file_path.lower().endswith(ext) for ext in extensions):\n",
        "                files.append(file_path)\n",
        "\n",
        "        files_length = len(files)\n",
        "        filename = None\n",
        "        for i, file_path in enumerate(files):\n",
        "            target = cv2.imread(file_path)\n",
        "            analysed_target = analyse_face(target, return_single_face=False)\n",
        "\n",
        "            if condition == \"Specific Face\":\n",
        "                swapped = swap_specific(\n",
        "                    analysed_source_specific,\n",
        "                    analysed_target,\n",
        "                    target,\n",
        "                    threshold=distance,\n",
        "                    face_enhance=face_enhance,\n",
        "                )\n",
        "            else:\n",
        "                swapped = swap_face_with_condition(\n",
        "                    analysed_source,\n",
        "                    analysed_target,\n",
        "                    target,\n",
        "                    condition,\n",
        "                    age,\n",
        "                    face_enhance=face_enhance,\n",
        "                )\n",
        "\n",
        "            filename = os.path.join(temp_path, os.path.basename(file_path))\n",
        "            cv2.imwrite(filename, swapped)\n",
        "            info_text = f\"### \\n ⌛ Processing file {i+1} of {files_length}\"\n",
        "            PREVIEW = swapped[:, :, ::-1]\n",
        "            yield info_text, *ui_before()\n",
        "\n",
        "        WORKSPACE = temp_path\n",
        "        OUTPUT_FILE = filename\n",
        "\n",
        "        tot_exec_time = time.time() - start_time\n",
        "        _min, _sec = divmod(tot_exec_time, 60)\n",
        "\n",
        "        yield f\"✔️ Completed in {int(_min)} min {int(_sec)} sec.\", *ui_after()\n",
        "\n",
        "    elif input_type == \"Stream\":\n",
        "        yield \"### \\n ⌛ Starting...\", *ui_before()\n",
        "        source = cv2.imread(source_path)\n",
        "        source = analyse_face(source, return_single_face=True)\n",
        "\n",
        "        global STREAMER\n",
        "        STREAMER = StreamerThread(src=directory_path)\n",
        "        STREAMER.start()\n",
        "        while True:\n",
        "            try:\n",
        "                target = STREAMER.frame\n",
        "                analysed_target = analyse_face(target, return_single_face=False)\n",
        "                if condition == \"Specific Face\":\n",
        "                    swapped = swap_specific(\n",
        "                        analysed_source_specific,\n",
        "                        analysed_target,\n",
        "                        target,\n",
        "                        threshold=distance,\n",
        "                        face_enhance=face_enhance,\n",
        "                    )\n",
        "                else:\n",
        "                    swapped = swap_face_with_condition(\n",
        "                        analysed_source,\n",
        "                        analysed_target,\n",
        "                        target,\n",
        "                        condition,\n",
        "                        age,\n",
        "                        face_enhance=face_enhance,\n",
        "                    )\n",
        "                PREVIEW = swapped[:, :, ::-1]\n",
        "                yield f\"Streaming...\", *ui_before()\n",
        "            except AttributeError:\n",
        "                yield \"Streaming...\", *ui_before()\n",
        "        STREAMER.stop()\n",
        "\n",
        "\n",
        "### Gradio change functions\n",
        "def update_radio(value):\n",
        "    if value == \"Image\":\n",
        "        return (\n",
        "            gr.update(visible=True),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "        )\n",
        "    elif value == \"Video\":\n",
        "        return (\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            gr.update(visible=False),\n",
        "        )\n",
        "    elif value == \"Directory\":\n",
        "        return (\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "        )\n",
        "    elif value == \"Stream\":\n",
        "        return (\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "        )\n",
        "\n",
        "\n",
        "def swap_option_changed(value):\n",
        "    if value == swap_options_list[1] or value == swap_options_list[2]:\n",
        "        return (\n",
        "            gr.update(visible=True),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "        )\n",
        "    elif value == swap_options_list[5]:\n",
        "        return (\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            gr.update(visible=False),\n",
        "        )\n",
        "    return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True)\n",
        "\n",
        "\n",
        "def video_changed(video_path):\n",
        "    sliders_update = gr.Slider.update\n",
        "    button_update = gr.Button.update\n",
        "    number_update = gr.Number.update\n",
        "\n",
        "    if video_path is None:\n",
        "        return (\n",
        "            sliders_update(minimum=0, maximum=0, value=0),\n",
        "            sliders_update(minimum=1, maximum=1, value=1),\n",
        "            number_update(value=1),\n",
        "        )\n",
        "    try:\n",
        "        clip = VideoFileClip(video_path)\n",
        "        fps = clip.fps\n",
        "        total_frames = clip.reader.nframes\n",
        "        clip.close()\n",
        "        return (\n",
        "            sliders_update(minimum=0, maximum=total_frames, value=0, interactive=True),\n",
        "            sliders_update(\n",
        "                minimum=0, maximum=total_frames, value=total_frames, interactive=True\n",
        "            ),\n",
        "            number_update(value=fps),\n",
        "        )\n",
        "    except:\n",
        "        return (\n",
        "            sliders_update(value=0),\n",
        "            sliders_update(value=0),\n",
        "            number_update(value=1),\n",
        "        )\n",
        "\n",
        "\n",
        "def analyse_settings_changed(detect_condition, detection_size, detection_threshold):\n",
        "    yield \"### \\n ⌛ Applying new values...\"\n",
        "    global FACE_ANALYSER\n",
        "    global DETECT_CONDITION\n",
        "    DETECT_CONDITION = detect_condition\n",
        "    FACE_ANALYSER = insightface.app.FaceAnalysis(name=\"buffalo_l\", providers=provider)\n",
        "    FACE_ANALYSER.prepare(\n",
        "        ctx_id=0,\n",
        "        det_size=(int(detection_size), int(detection_size)),\n",
        "        det_thresh=float(detection_threshold),\n",
        "    )\n",
        "    yield f\"### \\n ✔️ Applied detect condition:{detect_condition}, detection size: {detection_size}, detection threshold: {detection_threshold}\"\n",
        "\n",
        "\n",
        "def stop_running():\n",
        "    global STREAMER\n",
        "    if hasattr(STREAMER, \"stop\"):\n",
        "        STREAMER.stop()\n",
        "        STREAMER = None\n",
        "    return \"Cancelled\"\n",
        "\n",
        "\n",
        "def slider_changed(show_frame, video_path, frame_index):\n",
        "    if not show_frame:\n",
        "        return None, None\n",
        "    if video_path is None:\n",
        "        return None, None\n",
        "    clip = VideoFileClip(video_path)\n",
        "    frame = clip.get_frame(frame_index / clip.fps)\n",
        "    frame_array = np.array(frame)\n",
        "    clip.close()\n",
        "    return gr.Image.update(value=frame_array, visible=True), gr.Video.update(\n",
        "        visible=False\n",
        "    )\n",
        "\n",
        "\n",
        "def trim_and_reload(video_path, output_path, output_name, start_frame, stop_frame):\n",
        "    yield video_path, f\"### \\n ⌛ Trimming video frame {start_frame} to {stop_frame}...\"\n",
        "    try:\n",
        "        output_path = os.path.join(output_path, output_name)\n",
        "        trimmed_video = trim_video(video_path, output_path, start_frame, stop_frame)\n",
        "        yield trimmed_video, \"### \\n ✔️ Video trimmed and reloaded.\"\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        yield video_path, \"### \\n ❌ Video trimming failed. See console for more info.\"\n",
        "\n",
        "\n",
        "css = \"\"\"\n",
        "footer{display:none !important}\n",
        "\"\"\"\n",
        "\n",
        "### Gradio interface\n",
        "with gr.Blocks(css=css) as interface:\n",
        "    gr.Markdown(\"# 🗿 Swap Mukham\")\n",
        "    gr.Markdown(\"### Face swap app based on insightface inswapper.\")\n",
        "    with gr.Row():\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=0.4):\n",
        "                with gr.Tab(\"📄 Swap Condition\"):\n",
        "                    swap_option = gr.Radio(\n",
        "                        swap_options_list,\n",
        "                        show_label=False,\n",
        "                        value=swap_options_list[0],\n",
        "                        interactive=True,\n",
        "                    )\n",
        "                    age = gr.Number(\n",
        "                        value=25, label=\"Value\", interactive=True, visible=False\n",
        "                    )\n",
        "\n",
        "                with gr.Tab(\"🎚️ Detection Settings\"):\n",
        "                    detect_condition_dropdown = gr.Dropdown(\n",
        "                        detect_conditions,\n",
        "                        label=\"Condition\",\n",
        "                        value=DETECT_CONDITION,\n",
        "                        interactive=True,\n",
        "                        info=\"This condition is only used when multiple faces are detected on source or specific image.\",\n",
        "                    )\n",
        "                    detection_size = gr.Number(\n",
        "                        label=\"Detection Size\", value=640, interactive=True\n",
        "                    )\n",
        "                    detection_threshold = gr.Number(\n",
        "                        label=\"Detection Threshold\", value=0.5, interactive=True\n",
        "                    )\n",
        "                    apply_detection_settings = gr.Button(\"Apply settings\")\n",
        "\n",
        "                with gr.Tab(\"📤 Output Settings\"):\n",
        "                    output_directory = gr.Text(\n",
        "                        label=\"Output Directory\", value=os.getcwd(), interactive=True\n",
        "                    )\n",
        "                    output_name = gr.Text(\n",
        "                        label=\"Output Name\", value=\"Result\", interactive=True\n",
        "                    )\n",
        "                    keep_output_sequence = gr.Checkbox(\n",
        "                        label=\"Keep output sequence\", value=False, interactive=True\n",
        "                    )\n",
        "\n",
        "                with gr.Tab(\"🪄 Other Settings\"):\n",
        "                    enable_face_enhance = gr.Checkbox(\n",
        "                        label=\"Enhance face (GFPGAN)\", value=False, interactive=True\n",
        "                    )\n",
        "\n",
        "                source_image_input = gr.Image(\n",
        "                    label=\"Source face\", type=\"filepath\", interactive=True\n",
        "                )\n",
        "\n",
        "                with gr.Box(visible=False) as specific_face:\n",
        "                    for i in range(NUM_OF_SRC_SPECIFIC):\n",
        "                        idx = i + 1\n",
        "                        code = \"\\n\"\n",
        "                        code += f\"with gr.Tab(label='({idx})'):\"\n",
        "                        code += \"\\n\\twith gr.Row():\"\n",
        "                        code += f\"\\n\\t\\tsrc{idx} = gr.Image(interactive=True, type='numpy', label='Source Face {idx}')\"\n",
        "                        code += f\"\\n\\t\\ttrg{idx} = gr.Image(interactive=True, type='numpy', label='Specific Face {idx}')\"\n",
        "                        exec(code)\n",
        "\n",
        "                    distance_slider = gr.Slider(\n",
        "                        minimum=0,\n",
        "                        maximum=2,\n",
        "                        value=0.6,\n",
        "                        interactive=True,\n",
        "                        label=\"Distance\",\n",
        "                        info=\"Lower distance is more similar and higher distance is less similar to the target face.\",\n",
        "                    )\n",
        "\n",
        "                with gr.Group():\n",
        "                    input_type = gr.Radio(\n",
        "                        [\"Image\", \"Video\", \"Directory\", \"Stream\"],\n",
        "                        label=\"Target Type\",\n",
        "                        value=\"Video\",\n",
        "                    )\n",
        "\n",
        "                    with gr.Box(visible=False) as input_image_group:\n",
        "                        image_input = gr.Image(\n",
        "                            label=\"Target Image\", interactive=True, type=\"filepath\"\n",
        "                        )\n",
        "\n",
        "                    with gr.Box(visible=True) as input_video_group:\n",
        "                        video_input = gr.Video(\n",
        "                            label=\"Target Video Path\", interactive=True\n",
        "                        )\n",
        "                        with gr.Accordion(\"✂️ Trim video\", open=False):\n",
        "                            with gr.Column():\n",
        "                                with gr.Row():\n",
        "                                    set_slider_range_btn = gr.Button(\n",
        "                                        \"Set frame range\", interactive=True\n",
        "                                    )\n",
        "                                    show_trim_preview_btn = gr.Checkbox(\n",
        "                                        label=\"Show frame when slider change\",\n",
        "                                        value=True,\n",
        "                                        interactive=True,\n",
        "                                    )\n",
        "\n",
        "                                video_fps = gr.Number(\n",
        "                                    value=30,\n",
        "                                    interactive=False,\n",
        "                                    label=\"Fps\",\n",
        "                                    visible=False,\n",
        "                                )\n",
        "                                start_frame = gr.Slider(\n",
        "                                    minimum=0,\n",
        "                                    maximum=1,\n",
        "                                    value=0,\n",
        "                                    step=1,\n",
        "                                    interactive=True,\n",
        "                                    label=\"Start Frame\",\n",
        "                                    info=\"\",\n",
        "                                )\n",
        "                                end_frame = gr.Slider(\n",
        "                                    minimum=0,\n",
        "                                    maximum=1,\n",
        "                                    value=1,\n",
        "                                    step=1,\n",
        "                                    interactive=True,\n",
        "                                    label=\"End Frame\",\n",
        "                                    info=\"\",\n",
        "                                )\n",
        "                            trim_and_reload_btn = gr.Button(\n",
        "                                \"Trim and Reload\", interactive=True\n",
        "                            )\n",
        "\n",
        "                    with gr.Box(visible=False) as input_directory_group:\n",
        "                        direc_input = gr.Text(label=\"Path\", interactive=True)\n",
        "\n",
        "            with gr.Column(scale=0.6):\n",
        "                info = gr.Markdown(value=\"...\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    swap_button = gr.Button(\"✨ Swap\", variant=\"primary\")\n",
        "                    cancel_button = gr.Button(\"⛔ Cancel\")\n",
        "\n",
        "                preview_image = gr.Image(label=\"Output\", interactive=False)\n",
        "                preview_video = gr.Video(\n",
        "                    label=\"Output\", interactive=False, visible=False\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    output_directory_button = gr.Button(\"📂\", interactive=False, visible=False)\n",
        "                    output_video_button = gr.Button(\"🎬\", interactive=False, visible=False)\n",
        "\n",
        "                with gr.Column():\n",
        "                    gr.Markdown(\n",
        "                        '[![\"Buy Me A Coffee\"](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://www.buymeacoffee.com/harisreedhar)'\n",
        "                    )\n",
        "                    gr.Markdown(\n",
        "                        \"### [Source code](https://github.com/harisreedhar/Swap-Mukham) . [Disclaimer](https://github.com/harisreedhar/Swap-Mukham#disclaimer) . [Gradio](https://gradio.app/)\"\n",
        "                    )\n",
        "\n",
        "    set_slider_range_event = set_slider_range_btn.click(\n",
        "        video_changed,\n",
        "        inputs=[video_input],\n",
        "        outputs=[start_frame, end_frame, video_fps],\n",
        "    )\n",
        "\n",
        "    trim_and_reload_event = trim_and_reload_btn.click(\n",
        "        fn=trim_and_reload,\n",
        "        inputs=[video_input, output_directory, output_name, start_frame, end_frame],\n",
        "        outputs=[video_input, info],\n",
        "    )\n",
        "\n",
        "    start_frame_event = start_frame.release(\n",
        "        fn=slider_changed,\n",
        "        inputs=[show_trim_preview_btn, video_input, start_frame],\n",
        "        outputs=[preview_image, preview_video],\n",
        "        show_progress=False,\n",
        "    )\n",
        "\n",
        "    end_frame_event = end_frame.release(\n",
        "        fn=slider_changed,\n",
        "        inputs=[show_trim_preview_btn, video_input, end_frame],\n",
        "        outputs=[preview_image, preview_video],\n",
        "        show_progress=False,\n",
        "    )\n",
        "\n",
        "    input_type.change(\n",
        "        update_radio,\n",
        "        inputs=[input_type],\n",
        "        outputs=[input_image_group, input_video_group, input_directory_group],\n",
        "    )\n",
        "    swap_option.change(\n",
        "        swap_option_changed,\n",
        "        inputs=[swap_option],\n",
        "        outputs=[age, specific_face, source_image_input],\n",
        "    )\n",
        "\n",
        "    apply_detection_settings.click(\n",
        "        analyse_settings_changed,\n",
        "        inputs=[detect_condition_dropdown, detection_size, detection_threshold],\n",
        "        outputs=[info],\n",
        "    )\n",
        "\n",
        "    src_specific_inputs = []\n",
        "    gen_variable_txt = \",\".join(\n",
        "        [f\"src{i+1}\" for i in range(NUM_OF_SRC_SPECIFIC)]\n",
        "        + [f\"trg{i+1}\" for i in range(NUM_OF_SRC_SPECIFIC)]\n",
        "    )\n",
        "    exec(f\"src_specific_inputs = ({gen_variable_txt})\")\n",
        "    swap_inputs = [\n",
        "        input_type,\n",
        "        image_input,\n",
        "        video_input,\n",
        "        direc_input,\n",
        "        source_image_input,\n",
        "        output_directory,\n",
        "        output_name,\n",
        "        keep_output_sequence,\n",
        "        swap_option,\n",
        "        age,\n",
        "        distance_slider,\n",
        "        enable_face_enhance,\n",
        "        *src_specific_inputs,\n",
        "    ]\n",
        "\n",
        "    swap_outputs = [\n",
        "        info,\n",
        "        preview_image,\n",
        "        output_directory_button,\n",
        "        output_video_button,\n",
        "        preview_video,\n",
        "    ]\n",
        "\n",
        "    swap_event = swap_button.click(\n",
        "        fn=process, inputs=swap_inputs, outputs=swap_outputs, show_progress=False\n",
        "    )\n",
        "\n",
        "    cancel_button.click(\n",
        "        fn=stop_running,\n",
        "        inputs=None,\n",
        "        outputs=[info],\n",
        "        cancels=[\n",
        "            swap_event,\n",
        "            trim_and_reload_event,\n",
        "            set_slider_range_event,\n",
        "            start_frame_event,\n",
        "            end_frame_event,\n",
        "        ],\n",
        "        show_progress=False,\n",
        "    )\n",
        "    output_directory_button.click(\n",
        "        lambda: open_directory(path=WORKSPACE), inputs=None, outputs=None\n",
        "    )\n",
        "    output_video_button.click(\n",
        "        lambda: open_directory(path=OUTPUT_FILE), inputs=None, outputs=None\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interface.queue(concurrency_count=2, max_size=20).launch(share=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_wgCBbINu8b",
        "outputId": "09faf995-e487-48d7-eb59-4222884633ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run App\n",
        "\n"
      ],
      "metadata": {
        "id": "-Tn68Ayqdrlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python app.py"
      ],
      "metadata": {
        "id": "6dpBjbfVOrrc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}